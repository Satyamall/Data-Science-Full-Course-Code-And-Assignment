{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b41618d-cd37-4397-afef-85e8418a4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Ensure 'y' column exists\n",
    "if 'y' not in train_df.columns:\n",
    "    raise ValueError(\"Target variable 'y' not found in training data.\")\n",
    "\n",
    "# Separate target variable\n",
    "y = train_df['y']\n",
    "train_df.drop(columns=['ID', 'y'], inplace=True)\n",
    "test_ids = test_df['ID']\n",
    "test_df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    encoder = LabelEncoder()\n",
    "    all_values = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(all_values)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "\n",
    "# Function to remove zero-variance columns consistently\n",
    "def remove_zero_variance(df, reference_cols=None):\n",
    "    if reference_cols is None:\n",
    "        zero_variance_cols = df.var(numeric_only=True) == 0\n",
    "        reference_cols = df.columns[~zero_variance_cols]\n",
    "    return df[reference_cols], reference_cols\n",
    "\n",
    "# Apply zero-variance column removal\n",
    "train_df, reference_cols = remove_zero_variance(train_df)\n",
    "test_df = test_df[reference_cols]  # Ensure test set has the same features\n",
    "\n",
    "# Handle missing values using median imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_df[:] = imputer.fit_transform(train_df)\n",
    "test_df[:] = imputer.transform(test_df)\n",
    "\n",
    "# Ensure test set has the same features as training before PCA\n",
    "test_df = test_df.reindex(columns=train_df.columns, fill_value=0)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca_threshold = 0.95  # Explained variance ratio threshold\n",
    "pca = PCA(n_components=pca_threshold)\n",
    "X_pca = pca.fit_transform(train_df)\n",
    "test_pca = pca.transform(test_df)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Log feature consistency\n",
    "train_features = set(train_df.columns)\n",
    "test_features = set(test_df.columns)\n",
    "\n",
    "missing_in_test = train_features - test_features\n",
    "extra_in_test = test_features - train_features\n",
    "\n",
    "logging.info(f\"Missing in test: {missing_in_test}\")\n",
    "logging.info(f\"Extra in test: {extra_in_test}\")\n",
    "\n",
    "print(\"Preprocessing completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
